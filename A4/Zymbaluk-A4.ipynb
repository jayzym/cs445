{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\newcommand{\\xv}{\\mathbf{x}}\n",
    "\\newcommand{\\Xv}{\\mathbf{X}}\n",
    "\\newcommand{\\yv}{\\mathbf{y}}\n",
    "\\newcommand{\\zv}{\\mathbf{z}}\n",
    "\\newcommand{\\av}{\\mathbf{a}}\n",
    "\\newcommand{\\Wv}{\\mathbf{W}}\n",
    "\\newcommand{\\wv}{\\mathbf{w}}\n",
    "\\newcommand{\\tv}{\\mathbf{t}}\n",
    "\\newcommand{\\Tv}{\\mathbf{T}}\n",
    "\\newcommand{\\muv}{\\boldsymbol{\\mu}}\n",
    "\\newcommand{\\sigmav}{\\boldsymbol{\\sigma}}\n",
    "\\newcommand{\\phiv}{\\boldsymbol{\\phi}}\n",
    "\\newcommand{\\Phiv}{\\boldsymbol{\\Phi}}\n",
    "\\newcommand{\\Sigmav}{\\boldsymbol{\\Sigma}}\n",
    "\\newcommand{\\Lambdav}{\\boldsymbol{\\Lambda}}\n",
    "\\newcommand{\\half}{\\frac{1}{2}}\n",
    "\\newcommand{\\argmax}[1]{\\underset{#1}{\\operatorname{argmax}}}\n",
    "\\newcommand{\\argmin}[1]{\\underset{#1}{\\operatorname{argmin}}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4: Classification with QDA, LDA, and Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jared Zymbaluk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, you will make a new version of your ```NeuralNetwork``` class called ```NeuralNetworkClassifier```. You will then apply ```QDA```, ```LDA``` and your ```NeuralNetworkClassifier``` to a classification problem and discuss the results.  The ```tanh``` function will be used as the activation function for ```NeuralNetworkClassifier```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NeuralNetworkClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy your ```neuralnetworksA2.py``` into a new file named ```neuralnetworksA4.py```.  Define a new class named ```NeuralNetworkClassifier``` that extends ```NeuralNetwork```.  The following code cell indicates which methods you must override, with comments instructing you what you must do to complete it.  Add this class to your ```neuralnetworksA4.py``` file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test It"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import neuralnetworksA4 as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.arange(10).reshape((-1, 1))\n",
    "T = np.array([1]*5 + [2]*5).reshape((-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netc = nn.NeuralNetworkClassifier(X.shape[1], [5, 5], len(np.unique(T)))\n",
    "netc.train(X, T, 20)\n",
    "print(netc)\n",
    "print('T, Predicted')\n",
    "print(np.hstack((T, netc.use(X))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Addition to ```partition``` function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the keyword parameter ```classification``` with a default value of ```False``` to your ```partition``` function.  When its value is set to ```True``` your ```partition``` function must perform a stratified partitioning as illustrated in lecture notes [12 Introduction to Classification](http://nbviewer.ipython.org/url/www.cs.colostate.edu/~anderson/cs445/notebooks/12%20Introduction%20to%20Classification.ipynb)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlutilities as ml\n",
    "Xtrain, Ttrain, Xtest, Ttest = ml.partition(X, T, 0.6, classification=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ttrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ttest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example with toy data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the above data to compare QDA, LDA, and linear and nonlinear logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import qdalda\n",
    "qda = qdalda.QDA()\n",
    "qda.train(Xtrain, Ttrain)\n",
    "Ytrain = qda.use(Xtrain)\n",
    "Ytest = qda.use(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.hstack((Ttrain, Ytrain)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(Ttrain == Ytrain) / len(Ttrain) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.hstack((Ttest, Ytest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(Ttest == Ytest) / len(Ttest) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lda = qdalda.LDA()\n",
    "lda.train(Xtrain, Ttrain)\n",
    "Ytrain = lda.use(Xtrain)\n",
    "Ytest = lda.use(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.hstack((Ttrain, Ytrain)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.hstack((Ttest, Ytest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(Ttrain == Ytrain) / len(Ttrain) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(Ttest == Ytest) / len(Ttest) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml.confusionMatrix(Ttrain, Ytrain, [1, 2]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml.confusionMatrix(Ttest, Ytest, [1, 2]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netc = nn.NeuralNetworkClassifier(X.shape[1], [5, 5], len(np.unique(T)))\n",
    "netc.train(Xtrain, Ttrain, 100)\n",
    "print(netc)\n",
    "print('T, Predicted')\n",
    "Ytrain = netc.use(Xtrain)\n",
    "Ytest = netc.use(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.hstack((Ttrain, Ytrain)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.hstack((Ttest, Ytest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(Ttrain == Ytrain) / len(Ttrain) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(Ttest == Ytest) / len(Ttest) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml.confusionMatrix(Ttrain, Ytrain, [1, 2]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml.confusionMatrix(Ttest, Ytest, [1, 2]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that linear logistic regression can be applied by specifying 0 hidden units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netc = nn.NeuralNetworkClassifier(X.shape[1], 0, len(np.unique(T)))\n",
    "netc.train(Xtrain, Ttrain, 100)\n",
    "print(netc)\n",
    "print('T, Predicted')\n",
    "Ytrain = netc.use(Xtrain)\n",
    "Ytest = netc.use(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml.confusionMatrix(Ttrain, Ytrain, [1, 2]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml.confusionMatrix(Ttest, Ytest, [1, 2]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply to data from orthopedic patients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download ```column_3C_weka.csv``` from [this Kaggle site](https://www.kaggle.com/uciml/biomechanical-features-of-orthopedic-patients).  Use the column named ```class``` to create your target class labels. Apply QDA, LDA, linear logistic regression, and nonlinear logistic regression to this data.  Experiment with different hidden layer structures and numbers of iterations and describe what you find.\n",
    "\n",
    "Partition data into 80% for training and 20% for testing, with ```shuffle=True```.\n",
    "\n",
    "Print percents of training and testing samples correctly classified by QDA, LDA and various neural network classifiers.  Also print confusion matrices for training and for testing samples for each classifier.  Discuss the relative performance of your classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = np.genfromtxt('column_3C_weka.csv', dtype='str',delimiter=',',deletechars='\"')\n",
    "file = np.char.replace(file, '\"', '')\n",
    "file = np.char.replace(file, ' ', '')\n",
    "file = np.delete(file,0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "PT = np.take(file,[-1],1)\n",
    "PT = np.char.replace(PT, 'Hernia', '0')\n",
    "PT = np.char.replace(PT, 'Spondylolisthesis', '1')\n",
    "PT = np.char.replace(PT, 'Normal', '2')\n",
    "file = np.char.replace(file, ' ', '')\n",
    "PX = np.take(file,[0,1,2,3,4,5],1)\n",
    "PT = PT.astype(np.float)\n",
    "PX = PX.astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xtrain, Ttrain, Xtest, Ttest = ml.partition(PX, PT, 0.8, classification=True, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "nne = nn.NeuralNetworkClassifier(PX.shape[1], 0, len(np.unique(PT)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "nne.train(Xtrain, Ttrain, 100)\n",
    "#print('T, Predicted')\n",
    "#print(np.hstack((PT, nne.use(PX))))\n",
    "Ytrain = nne.use(Xtrain)\n",
    "Ytest = nne.use(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85.887096774193552"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(Ttrain == Ytrain) / len(Ttrain) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       1    2\n",
      "    ------------\n",
      " 1 | 95.0  4.2\n",
      " 2 |  2.5 82.5\n"
     ]
    }
   ],
   "source": [
    "ml.confusionMatrix(Ttrain, Ytrain, [1, 2]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75.806451612903231"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(Ttest == Ytest) / len(Ttest) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       1    2\n",
      "    ------------\n",
      " 1 | 80.0 13.3\n",
      " 2 | 10.0 90.0\n"
     ]
    }
   ],
   "source": [
    "ml.confusionMatrix(Ttest, Ytest, [1, 2]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, linear is pretty good with a rate of 85%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = qdalda.LDA()\n",
    "lda.train(Xtrain, Ttrain)\n",
    "Ytrain = lda.use(Xtrain)\n",
    "Ytest = lda.use(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80.2419354839\n",
      "74.1935483871\n",
      "       1    2\n",
      "    ------------\n",
      " 1 | 85.8  7.5\n",
      " 2 |  7.5 71.2\n",
      "       1    2\n",
      "    ------------\n",
      " 1 | 70.0 13.3\n",
      " 2 | 15.0 85.0\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(Ttrain == Ytrain) / len(Ttrain) * 100)\n",
    "print(np.sum(Ttest == Ytest) / len(Ttest) * 100)\n",
    "ml.confusionMatrix(Ttrain, Ytrain, [1, 2]);\n",
    "ml.confusionMatrix(Ttest, Ytest, [1, 2]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDA is also pretty good! with 80%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = qdalda.QDA()\n",
    "lda.train(Xtrain, Ttrain)\n",
    "Ytrain = lda.use(Xtrain)\n",
    "Ytest = lda.use(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86.6935483871\n",
      "77.4193548387\n",
      "       1    2\n",
      "    ------------\n",
      " 1 | 96.7  2.5\n",
      " 2 |  5.0 73.8\n",
      "       1    2\n",
      "    ------------\n",
      " 1 |100.0  0  \n",
      " 2 |  5.0 40.0\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(Ttrain == Ytrain) / len(Ttrain) * 100)\n",
    "print(np.sum(Ttest == Ytest) / len(Ttest) * 100)\n",
    "ml.confusionMatrix(Ttrain, Ytrain, [1, 2]);\n",
    "ml.confusionMatrix(Ttest, Ytest, [1, 2]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QDA is very good with 86%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nne2 = nn.NeuralNetworkClassifier(PX.shape[1], [1,1,1], len(np.unique(PT)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nne2.train(Xtrain, Ttrain, 100)\n",
    "#print('T, Predicted')\n",
    "#print(np.hstack((PT, nne.use(PX))))\n",
    "Ytrain = nne.use(Xtrain)\n",
    "Ytest = nne.use(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85.4838709677\n",
      "77.4193548387\n",
      "       1    2\n",
      "    ------------\n",
      " 1 | 91.7  5.8\n",
      " 2 |  5.0 87.5\n",
      "       1    2\n",
      "    ------------\n",
      " 1 | 93.3  6.7\n",
      " 2 |  0   70.0\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(Ttrain == Ytrain) / len(Ttrain) * 100)\n",
    "print(np.sum(Ttest == Ytest) / len(Ttest) * 100)\n",
    "ml.confusionMatrix(Ttrain, Ytrain, [1, 2]);\n",
    "ml.confusionMatrix(Ttest, Ytest, [1, 2]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The use of a hidden structure doesn't seem to change performance much"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like all classification methods were fairly good. Interesting way to go about classifying!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
