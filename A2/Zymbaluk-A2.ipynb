{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\newcommand{\\xv}{\\mathbf{x}}\n",
    "\\newcommand{\\Xv}{\\mathbf{X}}\n",
    "\\newcommand{\\yv}{\\mathbf{y}}\n",
    "\\newcommand{\\zv}{\\mathbf{z}}\n",
    "\\newcommand{\\av}{\\mathbf{a}}\n",
    "\\newcommand{\\Wv}{\\mathbf{W}}\n",
    "\\newcommand{\\wv}{\\mathbf{w}}\n",
    "\\newcommand{\\tv}{\\mathbf{t}}\n",
    "\\newcommand{\\Tv}{\\mathbf{T}}\n",
    "\\newcommand{\\muv}{\\boldsymbol{\\mu}}\n",
    "\\newcommand{\\sigmav}{\\boldsymbol{\\sigma}}\n",
    "\\newcommand{\\phiv}{\\boldsymbol{\\phi}}\n",
    "\\newcommand{\\Phiv}{\\boldsymbol{\\Phi}}\n",
    "\\newcommand{\\Sigmav}{\\boldsymbol{\\Sigma}}\n",
    "\\newcommand{\\Lambdav}{\\boldsymbol{\\Lambda}}\n",
    "\\newcommand{\\half}{\\frac{1}{2}}\n",
    "\\newcommand{\\argmax}[1]{\\underset{#1}{\\operatorname{argmax}}}\n",
    "\\newcommand{\\argmin}[1]{\\underset{#1}{\\operatorname{argmin}}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2: Neural Network Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Type your name here and rewrite all of the following sections.  Add more sections to present your code, results, and discussions.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this assignment is to learn about object-oriented programming in python and to gain some experience in comparing different sized neural networks when applied to a data set.\n",
    "\n",
    "Starting with the ```NeuralNetwork``` class from the lecture notes, you will create one new version of that class, apply it to a data set, and discuss the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start with the ```NeuralNetwork``` class defined in lecture notes 09. Put that class definition as written into *neuralnetworks.py* into your current directory.  Also place *mlutilities.py* from lecture notes 09 in your current directory. If this is done correctly, then the following code should run and produce results similar to what is shown here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neuralnetworks as nn\n",
    "\n",
    "X = np.arange(10).reshape((-1,1))\n",
    "T = np.sin(X)\n",
    "\n",
    "nnet = nn.NeuralNetwork(1, [10], 1)\n",
    "nnet.train(X, T, 100, verbose=True)\n",
    "nnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 12))\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.plot(nnet.getErrors())\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.plot(X, T, 'o-', label='Actual')\n",
    "plt.plot(X, nnet.use(X), 'o-', label='Predicted')\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "nnet.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's extract the parts of the neural network code that refer to the activation function and its derivative into two new methods.  Copy your file *neuralnetworks.py* into a new file named *neuralnetworksA2.py*.  Modify the code in *neuralnetworksA2.py* by adding these two methods to the ```NeuralNetwork``` class:\n",
    "\n",
    "    def activation(self, weighted_sum):\n",
    "        return np.tanh(weighted_sum)\n",
    "        \n",
    "    def activationDerivative(self, activation_value):\n",
    "        return 1 - activation_value * activation_value\n",
    "        \n",
    "Now replace the code in the appropriate places in the ```NeuralNetwork``` class so that ```np.tanh``` is replaced with a call to the ```self.activation``` method and its derivative is replaced by calls to ```self.activationDerivative```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import neuralnetworksA2 as nn2\n",
    "\n",
    "nnet = nn2.NeuralNetwork(1, [10], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[nnet.activation(s) for s in [-2, -0.5, 0, 0.5, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[nnet.activationDerivative(nnet.activation(s)) for s in [-2, -0.5, 0, 0.5, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nnet.train(X, T, 100, verbose=True)\n",
    "nnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 12))\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.plot(nnet.getErrors())\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.plot(X, T, 'o-', label='Actual')\n",
    "plt.plot(X, nnet.use(X), 'o-', label='Predicted')\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "nnet.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Performance with Different Hidden Layer Structures and Numbers of Training Iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example with Toy Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using your new ```NeuralNetwork``` class, you can compare the error obtained on a given data set by looping over various hidden layer structures.  Here is an example using the simple toy data from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "nRows = X.shape[0]\n",
    "rows = np.arange(nRows)\n",
    "np.random.shuffle(rows)\n",
    "nTrain = int(nRows * 0.8)\n",
    "trainRows = rows[:nTrain]\n",
    "testRows = rows[nTrain:]\n",
    "Xtrain, Ttrain = X[trainRows, :], T[trainRows, :]\n",
    "Xtest, Ttest = X[testRows, :], T[testRows, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain.shape, Ttrain.shape, Xtest.shape, Ttest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rmse(A, B):\n",
    "    return np.sqrt(np.mean((A - B)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "errors = []\n",
    "hiddens = [0] + [[nu] * nl for nu in [1, 5, 10, 20, 50] for nl in [1, 2, 3, 4, 5]]\n",
    "print('hiddens =', hiddens)\n",
    "for hids in hiddens: \n",
    "    nnet = nn.NeuralNetwork(Xtrain.shape[1], hids, Ttrain.shape[1])\n",
    "    nnet.train(Xtrain, Ttrain, 500)\n",
    "    errors.append([hids, rmse(Ttrain, nnet.use(Xtrain)), rmse(Ttest, nnet.use(Xtest))])\n",
    "errors = pd.DataFrame(errors)\n",
    "print(errors)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.plot(errors.values[:, 1:], 'o-')\n",
    "plt.legend(('Train RMSE', 'Test RMSE'))\n",
    "plt.xticks(range(errors.shape[0]), hiddens, rotation=30, horizontalalignment='right')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this data (and the random shuffling of the data used when this notebook was run), `[10, 10, 10, 10]` produced the lowest test error.  \n",
    "\n",
    "Now, using the best hidden layer structure found, write the code that varies the number of training iterations. The results you get will be different from the ones shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = []\n",
    "nIterationsList = [10, 20, 50, 100, 150, 200, 250, 300, 350, 400, 450, 500]\n",
    "\n",
    "for n in nIterationsList:\n",
    "    nnet = nn.NeuralNetwork(Xtrain.shape[1], [50], Ttrain.shape[1])\n",
    "    nnet.train(Xtrain, Ttrain, n)\n",
    "    errors.append([[50], rmse(Ttrain, nnet.use(Xtrain)), rmse(Ttest, nnet.use(Xtest))])\n",
    "errors = pd.DataFrame(errors)\n",
    "print(nIterationsList)\n",
    "print(errors)\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.plot(errors.values[:, 1:], 'o-')\n",
    "plt.legend(('Train RMSE', 'Test RMSE'))\n",
    "plt.xticks(range(errors.shape[0]), nIterationsList) # , rotation=30, horizontalalignment='right')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments wtih Automobile Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, repeat the above steps with the automobile mpg data we have used before.  Set it up to use \n",
    "\n",
    "  * cylinders,\n",
    "  * displacement,\n",
    "  * weight,\n",
    "  * acceleration,\n",
    "  * year, and\n",
    "  * origin\n",
    "  \n",
    "as input variables, and\n",
    "\n",
    "  * mpg\n",
    "  * horsepower\n",
    "  \n",
    "as output variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeMPGData(filename='auto-mpg.data'):\n",
    "    def missingIsNan(s):\n",
    "        return np.nan if s == b'?' else float(s)\n",
    "    data = np.loadtxt(filename, usecols=range(8), converters={3: missingIsNan})\n",
    "    print(\"Read\",data.shape[0],\"rows and\",data.shape[1],\"columns from\",filename)\n",
    "    goodRowsMask = np.isnan(data).sum(axis=1) == 0\n",
    "    data = data[goodRowsMask,:]\n",
    "    print(\"After removing rows containing question marks, data has\",data.shape[0],\"rows and\",data.shape[1],\"columns.\")\n",
    "    X = data[:,1:]\n",
    "    X = np.delete(X,2,axis=1)\n",
    "    T = data[:,0:1]\n",
    "    T = np.append(T,data[:,3:4],axis=1)\n",
    "    Xnames =  ['bias', 'cylinders','displacement','weight','acceleration','year','origin']\n",
    "    Tname = ['mpg','horsepower']\n",
    "    return X,T,Xnames,Tname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xa,Ta,Xanames,Taname = makeMPGData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "naRows = Xa.shape[0]\n",
    "arows = np.arange(naRows)\n",
    "np.random.shuffle(arows)\n",
    "naTrain = int(naRows * 0.8)\n",
    "atrainRows = arows[:naTrain]\n",
    "atestRows = arows[naTrain:]\n",
    "Xatrain, Tatrain = Xa[atrainRows, :], Ta[atrainRows, :]\n",
    "Xatest, Tatest = Xa[atestRows, :], Ta[atestRows, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain.shape, Ttrain.shape, Xtest.shape, Ttest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aerrors = []\n",
    "ahiddens = [0] + [[nu] * nl for nu in [1, 5, 10, 20, 50] for nl in [1, 2, 3, 4, 5]]\n",
    "print('hiddens =', ahiddens)\n",
    "for hids in ahiddens: \n",
    "    annet = nn.NeuralNetwork(Xatrain.shape[1], hids, Tatrain.shape[1])\n",
    "    annet.train(Xatrain, Tatrain, 500)\n",
    "    aerrors.append([hids, rmse(Tatrain, annet.use(Xatrain)), rmse(Tatest, annet.use(Xatest))])\n",
    "aerrors = pd.DataFrame(aerrors)\n",
    "print(aerrors)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.plot(aerrors.values[:, 1:], 'o-')\n",
    "plt.legend(('Train RMSE', 'Test RMSE'))\n",
    "plt.xticks(range(aerrors.shape[0]), ahiddens, rotation=30, horizontalalignment='right')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^After running this several times, it appears that the structures that most often show up as the best (lowest RMSE) are [5,5] and [50,50]. [50] showed up sometimes. Overal it seemed to vary a bit. I'll choose [5,5] as my structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aerrors = []\n",
    "anIterationsList = [10, 20, 50, 100, 150, 200, 250, 300, 350, 400, 450, 500]\n",
    "\n",
    "for n in anIterationsList:\n",
    "    annet = nn.NeuralNetwork(Xatrain.shape[1], [5,5], Tatrain.shape[1])\n",
    "    annet.train(Xatrain, Tatrain, n)\n",
    "    aerrors.append([[5,5], rmse(Tatrain, annet.use(Xatrain)), rmse(Tatest, annet.use(Xatest))])\n",
    "aerrors = pd.DataFrame(aerrors)\n",
    "print(anIterationsList)\n",
    "print(aerrors)\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.plot(aerrors.values[:, 1:], 'o-')\n",
    "plt.legend(('Train RMSE', 'Test RMSE'))\n",
    "plt.xticks(range(aerrors.shape[0]), anIterationsList) # , rotation=30, horizontalalignment='right')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^After determining my best hidden structure to be [5,5]. I ran the iterations several times. While the results were all over the place. Most often the best RMSE was greater than 200. The graph will usually fluctuate after 200, and then settle down and get closer to zero as the number of iterations approached 500. Sometimes 500 would even be the best number of iterations. Overall I think it's fair to say that a higher number of iterations tends to result in a better score."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
